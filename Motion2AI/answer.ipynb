{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a399e8a-8b6b-45ee-9441-d492625161d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32dcf1e6-b6dd-49d1-9299-1f2493421d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import datetime\n",
    "from itertools import groupby, chain\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205d3a4c-fbf6-49a6-b81f-10c668952fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d2bbf4d-fc00-4b8c-8b83-e7c375a44dde",
   "metadata": {},
   "source": [
    "# Exam\n",
    "\n",
    "## Background\n",
    "- Motion2AI는 머신러닝 애플리케이션을 구축하고 사용하여, 산업용 차량이 사용 중인지(= loaded) 유휴 상태인지(= not loaded) 이해합니다.\n",
    "- 머신러닝 애플리케이션은 100% 정확하지 않으며, 잘못된 머신러닝 예측으로 인해, 머신러닝 측정 값(`loaded` column)은 flickering 되고 있습니다. 즉, `loaded` 데이터에 노이즈가 있습니다.\n",
    "- 우리의 목표는 데이터에서 노이즈를 제거하기 위해, 파이썬에서 간단한 시간별 필터링 로직(time-wise filtering logic)을 만드는 것입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Description\n",
    "1. vehicle_name\n",
    "    - 1~4까지 vehicle ID\n",
    "1. datetime\n",
    "    - 데이터가 기록된 시각을 `YYYY-MM-DD hh:mm:ss`로 저장\n",
    "1. loaded\n",
    "    - 머신러닝 알고리즘이 지게차에 물건이 적재되었는지(`loaded`) 여부를 감지\n",
    "1. normalized_loaded\n",
    "    - `loaded` column의 post-processed 데이터\n",
    "\n",
    "---\n",
    "\n",
    "## Problem\n",
    "- 'loaded' 데이터에 대한 머신러닝 알고리즘은 시간이 지남에 따라 노이즈가 끼고, flickering 될 수 있습니다.\n",
    "- 노이즈를 제거하기 위해 `loaded` 데이터를 처리하기를 원합니다.\n",
    "- 파이썬 코드의 결과는 `normalized_loaded`(= ground truth)의 값과 동일할 것으로 예상됩니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "1. `loaded` status는 1 or 0입니다.\n",
    "1. `loaded` 값이 5초 이상 변경되지 않으면, `normalized_loaded` 값은 `loaded` 값과 동일합니다.\n",
    "    - == `loaded` 값이 5초 이상 유지되면, `normalized_loaded` 값은 `loaded` 값과 같음 \n",
    "1. `loaded` 값이 4초 이내로 변경되면, 카운트되지 않으며, `normalized_loaded` 값은 이전 `normalized_loaded` 값입니다.\n",
    "    - == `loaded` 값이 4초 이내로 바뀌면, flickering 됐다고 생각하고, 카운트 하지 않음\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**`normalized_loaded`를 생성하는 파이썬 함수를 작성하세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8eb877-5a59-4204-8336-3888171e0f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d3dc317-f57e-4bef-8773-2d2692064e9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data issue\n",
    "\n",
    "1. 데이터가 수집되지 않은 경우가 있음 (== 모든 데이터가 1초 간격인 것이 아님)\n",
    "1. 'normalized_loaded' column이 ground truth가 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70e7a580-e553-4e8f-a062-a10a046ca4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "def check_issue_1(time_series, sec=4):\n",
    "    \"\"\"데이터가 sec초 보다 크게 차이나는 경우의 수를 카운트\"\"\"\n",
    "    issue = []\n",
    "    prev_datetime = time_series[0]\n",
    "    \n",
    "    for now_datetime in time_series[1:]:\n",
    "        diff = now_datetime - prev_datetime\n",
    "        if diff > datetime.timedelta(seconds=sec):\n",
    "            issue.append(diff)\n",
    "        prev_datetime = now_datetime\n",
    "        \n",
    "    print(len(issue))\n",
    "\n",
    "    \n",
    "def check_issue_2(norm_series):\n",
    "    \"\"\"normalized_loaded에서 5초 이상 유지되지 않았는데 값이 바뀐 경우의 수를 카운트\"\"\"\n",
    "    prev = norm_series[0]\n",
    "    cnt = 1\n",
    "    \n",
    "    counts = []\n",
    "    for x in norm_series[1:]:\n",
    "        if x == prev:\n",
    "            cnt += 1\n",
    "            continue\n",
    "        else:\n",
    "            counts.append(cnt)\n",
    "            cnt = 1\n",
    "            prev = x\n",
    "    counts.append(cnt)\n",
    "    assert sum(counts) == len(norm_series)\n",
    "\n",
    "    issue = [cnt for cnt in counts if cnt < 5]\n",
    "    print(len(issue))\n",
    "\n",
    "\n",
    "def check_issues():\n",
    "    data_path = './pose_example.csv'\n",
    "    vehicle_id = 1\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    temp_df = df[df['vehicle_name'] == vehicle_id]\n",
    "    temp_time = temp_df['datetime']\n",
    "    temp_norm_loaded = temp_df['normalized_loaded']\n",
    "    \n",
    "    check_issue_1(temp_time)\n",
    "    check_issue_2(temp_norm_loaded)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2af338-70aa-42f5-92e9-b7746df1a4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a9013da-7b83-43bf-9520-80c417a30de2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03df2eb5-6242-4d5c-89b2-92302c7d85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import datetime\n",
    "from itertools import groupby, chain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d21fd89-1ce1-4521-871f-ea3029be9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_vehicle_id(df: pd.DataFrame) -> Dict[int, pd.DataFrame]:\n",
    "    \"\"\"vehicle id 별로 데이터 쪼개기\"\"\"\n",
    "    df_dict = {}\n",
    "    vehicle_id_list = df['vehicle_name'].unique()\n",
    "    for vid in vehicle_id_list:\n",
    "        new_df = df[df['vehicle_name'] == vid]\n",
    "        df_dict[vid] = new_df\n",
    "    assert df.shape[0] == sum(vdf.shape[0] for vdf in df_dict.values())\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "def split_by_time_diff(df_dict: Dict[int, pd.DataFrame], \n",
    "                       sec=4) -> Dict[int, List[pd.DataFrame]]:\n",
    "    \"\"\"데이터 기록(datetime) 간격이 5초 이상 차이나는 부분 데이터 쪼개기\"\"\"\n",
    "    new_df_dict = {}\n",
    "    \n",
    "    # vehicle id를 반복\n",
    "    for vehicle_id, vdf in df_dict.items():\n",
    "        splitted_df_list = []\n",
    "        prev_index = 0\n",
    "        prev_datetime = vdf.iloc[0]['datetime']\n",
    "        \n",
    "        # row를 반복\n",
    "        for idx, row in enumerate(vdf.iloc[1:].itertuples(), 1):\n",
    "            now_datetime = row.datetime\n",
    "            diff = now_datetime - prev_datetime\n",
    "            if diff > datetime.timedelta(seconds=sec):\n",
    "                splitted_df_list.append(vdf.iloc[prev_index: idx])\n",
    "                prev_index = idx\n",
    "            prev_datetime = row.datetime\n",
    "        splitted_df_list.append(vdf.iloc[prev_index:])\n",
    "        new_df_dict[vehicle_id] = splitted_df_list\n",
    "        assert vdf.shape[0] == sum(sdf.shape[0] for sdf in splitted_df_list)\n",
    "    return new_df_dict\n",
    "\n",
    "\n",
    "def remove_flickering(df_dict: Dict[int, List[pd.DataFrame]]) -> List[int]:\n",
    "    \"\"\"5초 이상 유지되지 않은 flickering하는 부분 제거\"\"\"\n",
    "    all_status = []\n",
    "    \n",
    "    # vehicle id를 반복\n",
    "    for vehicle_id, df_list in df_dict.items():\n",
    "        \n",
    "        # splitted df를 반복\n",
    "        for datum in df_list:\n",
    "            loaded = list(datum['loaded'])\n",
    "            dup_cnt = [sum(1 for _ in group) for _, group in groupby(loaded)]\n",
    "            dup_val = [loaded[0]]\n",
    "            \n",
    "            for i in range(len(dup_cnt)-1):\n",
    "                if dup_val[-1] == 0:\n",
    "                    dup_val.append(1)\n",
    "                else:\n",
    "                    dup_val.append(0)\n",
    "            \n",
    "            true_status = []\n",
    "            for val, cnt in zip(dup_val, dup_cnt):\n",
    "                if not true_status or cnt >= 5:\n",
    "                    true_status.extend([val]*cnt)\n",
    "                else:\n",
    "                    true_status.extend([true_status[-1]]*cnt)\n",
    "            all_status.append(true_status)\n",
    "    return list(chain.from_iterable(all_status))\n",
    "\n",
    "\n",
    "def run(data_path: str) -> List[int]:\n",
    "    \"\"\"전체 프로세스 실행\"\"\"\n",
    "    raw_df = pd.read_csv(data_path)\n",
    "    raw_df['datetime'] = pd.to_datetime(raw_df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df = raw_df.sort_values(['vehicle_name', 'datetime'])    \n",
    "\n",
    "    df_dict = split_by_vehicle_id(df)\n",
    "    df_dict = split_by_time_diff(df_dict)\n",
    "    result = remove_flickering(df_dict)\n",
    "    # df['result'] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0fec81d-0a62-4e6c-916e-a3365892bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run('./pose_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132eb105-66ca-44a1-bebb-8cec19764f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
